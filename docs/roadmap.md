---
sidebar_position: 9
title: "ğŸ›£ï¸ Roadmap"
---

# ğŸ›£ï¸ Roadmap

:::note Last updated
`May 8, 2023`
:::

The goal of this doc is to align *core* and *community* efforts for the project and to share what's in store for this year!

**Sections**
- What is the core Chroma team working on right now?
- What will Chroma prioritize over the next 6mo?
- What areas are great for community contributions?

## What is the core Chroma team working on right now?

This week we are working through the backlog of Github issues and PRs and adding lots of new functionality. A few issues we are looking to address:
- ğŸ A more minimal python-client only build target
- âœ‹ Google PaLM embedding support
- ğŸ£ OpenAI ChatGPT Retrieval Plugin
- ğŸ‹ Support for Conda and Dockerhub
- and more! 

## What did the Chroma team just complete?

**âœ… A Robust Test Suite**

The core team implemented a [hypothesis-based](https://hypothesis.readthedocs.io/en/latest/) testing suite to battle-harden Chromaâ€™s APIs. This was a big undertaking. We invested the time in this now to enable high development velocity in the near future and to be able to accept community contributions without fear of regressions or bugs.

## What will Chroma prioritize over the next 6mo?

**Next Milestone: â˜ï¸ Launch Hosted Chroma**

- ğŸ•¸ï¸ Replacing Clickhouse with a custom Distributed System
- ğŸŒ©ï¸ Standing up that distributed system as a managed service (aka "Hosted Chroma" - [sign up for waitlist](https://airtable.com/shrOAiDUtS2ILy5vZ)!)

**Areas we will invest in**

Not an exhaustive list, but these are some of the core teamâ€™s biggest priorities over the coming few months. Use caution when contributing in these areas and please check-in with the core team first.

- â© **Workflow**: Building tools for answer questions like: what embedding model should I use? And how should I chunk up my documents?
- ğŸŒŒ **Visualization**: Building visualization tool to give developers greater intuition embedding spaces
- ğŸ”€ **Query Planner**: Building tools to enable per-query and post-query transforms
- ğŸ”§ **Developer experience**: Extending Chroma into a CLI
- ğŸ“¦ **Easier Data Sharing**: Working on formats for serialization and easier data sharing of embedding Collections
- ğŸ” **Improving recall**: Fine-tuning embedding transforms through human feedback
- ğŸ§  **Analytical horsepower**: Clustering, deduplication, classification and more

## What areas are great for community contributions?

This is where you have a lot more free rein to contribute (without having to sync with us first)!

If you're unsure about your contribution idea, feel free to chat with us (@chroma) in the `#general` channel in [our Discord](https://discord.gg/rahcMUU5XV)! We'd love to support you however we can.

### âš™ï¸ Example Templates

We can always use [more integrations](https://docs.trychroma.com/integrations) with the rest of the AI ecosystem. Please let us know if you're working on one and need help!

Other great starting points for Chroma (please send PRs for more [here](https://github.com/chroma-core/docs/tree/swyx/addRoadmap/docs)):
- [Google Colab](https://colab.research.google.com/drive/1QEzFyqnoFxq7LUGyP1vzR4iLt9PpCDXv?usp=sharing)
- [Replit Template](https://replit.com/@swyx/BasicChromaStarter?v=1)

For those integrations we do have, like `LangChain` and `LlamaIndex`, we do always want more tutorials, demos, workshops, videos, and podcasts (we've done some pods [on our blog](https://trychroma.com/blog)).

### ğŸ“¦ Example Datasets

It doesnâ€™t make sense for developers to embed the same information over and over again with the same embedding model.

We'd like suggestions for:

- "small" (<100 rows)
- "medium" (<5MB)
- "large" (>1GB)

datasets for people to stress test Chroma in a variety of scenarios.

### âš–ï¸ Embeddings Comparison

Chroma does ship with Sentence Transformers by default for embeddings, but we are otherwise unopinionated about what embeddings you use. Having a library of information that has been embedded with many models, alongside example query sets would make it much easier for empirical work to be done on the effectiveness of various models across different domains.

- [Preliminary reading on Embeddings](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526?gi=ee46baab0d8f)
- [Huggingface Benchmark of a bunch of Embeddings](https://huggingface.co/blog/mteb)
- [notable issues with GPT3 Embeddings](https://twitter.com/Nils_Reimers/status/1487014195568775173) and alternatives to consider

### âš—ï¸ Experimental Algorithms

If you have a research background, please consider adding to our `ExperimentalAPI`s. For example:

- Projections (t-sne, UMAP, the new hotness, the one you just wrote) and Lightweight visualization
- Clustering (HDBSCAN, PCA)
- Deduplication
- Multimodal (CLIP)
- Fine-tuning manifold with human feedback [eg](https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb)
- Expanded vector search (MMR, Polytope)
- Your research

### ğŸ§‘â€ğŸ’»ï¸ Additional Client SDKs

We will be happy to work with people maintaining additional client SDKs as part of the community. Specifically: 

- Ruby 
- Clojure 
- Elixir

You can find the REST OpenAPI spec at `localhost:8000/openapi.json` when the backend is running.

Please [reach out](https://discord.gg/MMeYNTmh3x) and talk to us before you get too far in your projects so that we can offer technical guidance/align on roadmap.
